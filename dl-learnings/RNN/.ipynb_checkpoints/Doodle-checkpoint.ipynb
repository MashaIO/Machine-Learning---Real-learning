{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intellisence (Learning for the dat :-)\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traditional neural networks can’t do this, and it seems like a major shortcoming. For example, imagine you want to \n",
    "#classify what kind of event is happening at every point in a movie. It’s unclear how a traditional neural \n",
    "#network could use its reasoning about previous events in the film to inform later ones.\n",
    "\n",
    "#Recurrent neural networks address this issue. They are networks with loops in them, allowing information to persist.\n",
    "\n",
    "#LSTMs are explicitly designed to avoid the long-term dependency problem. \n",
    "#Remembering information for long periods of time is practically their default behavior, \n",
    "#not something they struggle to learn!\n",
    "\n",
    "# Best Read http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "# THE BELOW PROBLEM CAN BE SOLVED USING CNN ALSO. \n",
    "# But it is worth to solve using LSTM.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decalring Model Parameters\n",
    "batch_size = 4096\n",
    "STROKE_COUNT = 196\n",
    "TRAIN_SAMPLES = 750\n",
    "VALID_SAMPLES = 75\n",
    "TEST_SAMPLES = 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing standard libraries \n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#A metric is a function that is used to judge the performance of your model. \n",
    "#Metric functions are to be supplied in the metrics parameter when a model is compiled.\n",
    "\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "\n",
    "#Available metrics\n",
    "#binary_accuracy , categorical_accuracy, sparse_categorical_accuracy, top_k_categorical_accuracy, \n",
    "#sparse_top_k_categorical_accuracy\n",
    "\n",
    "#AND \n",
    "\n",
    "#Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(x,y): return top_k_categorical_accuracy(x,y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A callback is a set of functions to be applied at given stages of the training procedure. \n",
    "#You can use callbacks to get a view on internal states and statistics of the model during training. \n",
    "#You can pass a list of callbacks (as the keyword argument callbacks) to the .fit() method \n",
    "#of the Sequential or Model classes. The relevant methods of the callbacks will then be called \n",
    "#at each stage of the training.\n",
    "\n",
    "# ModelCheckpoint - Save the model after every epoch.\n",
    "# LearningRateScheduler - Learning rate scheduler.\n",
    "# EarlyStopping - top training when a monitored quantity has stopped improving.\n",
    "# ReduceLROnPlateau - Reduce learning rate when a metric has stopped improving.\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from glob import glob\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for available GPU, but for our learnings lets skip this.\n",
    "def get_available_gpus():\n",
    "    from tensorflow.python.client import device_lib\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\..\\\\data'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\..\\\\data\\\\doodleoutput\\test_simplified.csv'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ast.literal_eval raises an exception if the input isn't a valid Python datatype, so the code won't be executed if it's not.\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\..\\\\data\\\\doodle-dataset\\\\airplane.csv',\n",
       " '..\\\\..\\\\data\\\\doodle-dataset\\\\alarm clock.csv',\n",
       " '..\\\\..\\\\data\\\\doodle-dataset\\\\ambulance.csv',\n",
       " '..\\\\..\\\\data\\\\doodle-dataset\\\\animal migration.csv']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data path\n",
    "ALL_TRAIN_PATHS = glob('..\\..\\data\\doodle-dataset\\*.csv')\n",
    "ALL_TRAIN_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_NAMES = ['countrycode', 'drawing', 'key_id', 'recognized', 'timestamp', 'word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'samples': 750, 'start_row': 0, 'max_rows': 1125}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_args = dict(samples=TRAIN_SAMPLES, \n",
    "                  start_row=0, \n",
    "                  max_rows=int(TRAIN_SAMPLES*1.5))\n",
    "train_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'samples': 75, 'start_row': 1126, 'max_rows': 100}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_args = dict(samples=VALID_SAMPLES, \n",
    "                  start_row=train_args['max_rows']+1, \n",
    "                  max_rows=VALID_SAMPLES+25)\n",
    "valid_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'samples': 50, 'start_row': 1226, 'max_rows': 75}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_args = dict(samples=TEST_SAMPLES, \n",
    "                 start_row=valid_args['max_rows']+train_args['max_rows']+1, \n",
    "                 max_rows=TEST_SAMPLES+25)\n",
    "test_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the csv Files \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\..\\\\data\\\\doodle-dataset\\\\airplane.csv',\n",
       " '..\\\\..\\\\data\\\\doodle-dataset\\\\alarm clock.csv',\n",
       " '..\\\\..\\\\data\\\\doodle-dataset\\\\ambulance.csv',\n",
       " '..\\\\..\\\\data\\\\doodle-dataset\\\\animal migration.csv']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_TRAIN_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for eachDrawingItem in full_df['drawing']:\n",
    "def _stack_it(raw_strokes):\n",
    "    #print(eachDrawingItem)\n",
    "    stroke_vec = literal_eval(raw_strokes) # string->list\n",
    "    #print(stroke_vec)\n",
    "    # unwrap the list - Here they are converting 2 dimension objects to 3 dimesnionsby and for the 3rd y axis \n",
    "    # filling with 0 to  3 \n",
    "    in_strokes = [(xi,yi,i)  \n",
    "     for i,(x,y) in enumerate(stroke_vec) \n",
    "     for xi,yi in zip(x,y)]\n",
    "    #print(in_strokes)\n",
    "    # joins the sequence of arrays along a new axis.\n",
    "    c_strokes = np.stack(in_strokes)\n",
    "    #print(c_strokes)\n",
    "    #print(c_strokes[:,2])\n",
    "    \n",
    "    #>>> x = np.array([1, 2, 4, 7, 0])\n",
    "    #>>> np.diff(x)\n",
    "        #array([ 1,  2,  3, -7])\n",
    "    #>>> np.diff(x, n=2)\n",
    "    #array([  1,   1, -10])\n",
    "    \n",
    "    #print(np.diff(c_strokes[:,2]))\n",
    "    #print([1]+np.diff(c_strokes[:,2]).tolist())\n",
    "    c_strokes[:,2] = [1]+np.diff(c_strokes[:,2]).tolist()\n",
    "    c_strokes[:,2] += 1 # since 0 is no stroke\n",
    "    #print(c_strokes[:,2])\n",
    "    #print(c_strokes.swapaxes(0, 1))\n",
    "    # pad_sequences is used to ensure that all sequences in a list have the same length. \n",
    "    #By default this is done by padding 0 in the beginning of each sequence until each \n",
    "    # sequence has the same length as the longest sequence.\n",
    "    return pad_sequences(c_strokes.swapaxes(0, 1), maxlen=196, padding='post').swapaxes(0, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_batch(samples=5, \n",
    "               start_row=0,\n",
    "               max_rows = 1000):\n",
    "    \n",
    "    # For Ebvery files in the location. ( Training data set)\n",
    "    out_df_list = []\n",
    "    for c_path in ALL_TRAIN_PATHS:\n",
    "            #c_df = pd.read_csv(c_path, nrows=1125, skiprows=0)\n",
    "            c_df = pd.read_csv(c_path, nrows=max_rows, skiprows=start_row)\n",
    "            #print(c_df) \n",
    "            c_df.columns=COL_NAMES\n",
    "            #print(c_df)\n",
    "            # Just taking 750 records in each file (airplane, clock)\n",
    "            #out_df_list += [c_df.sample(750)[['drawing', 'word']]]\n",
    "            out_df_list += [c_df.sample(samples)[['drawing', 'word']]]\n",
    "\n",
    "    full_df = pd.concat(out_df_list)\n",
    "    #print(full_df)\n",
    "    full_df['drawing'] = full_df['drawing'].\\\n",
    "            map(_stack_it)\n",
    "\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = read_batch(**train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                drawing              word\n",
      "678   [[91, 89, 2], [94, 100, 1], [114, 120, 1], [12...          airplane\n",
      "28    [[39, 150, 2], [117, 168, 1], [182, 139, 1], [...          airplane\n",
      "62    [[16, 39, 2], [32, 38, 1], [49, 25, 1], [47, 2...          airplane\n",
      "560   [[54, 36, 2], [35, 50, 1], [7, 61, 1], [0, 71,...          airplane\n",
      "404   [[36, 89, 2], [56, 70, 1], [88, 55, 1], [145, ...          airplane\n",
      "892   [[147, 43, 2], [47, 73, 1], [16, 73, 1], [4, 7...          airplane\n",
      "195   [[114, 101, 2], [33, 107, 1], [9, 123, 1], [0,...          airplane\n",
      "91    [[208, 65, 2], [158, 65, 1], [111, 72, 1], [25...          airplane\n",
      "396   [[103, 68, 2], [92, 26, 1], [103, 4, 1], [117,...          airplane\n",
      "1034  [[37, 11, 2], [42, 44, 1], [49, 52, 1], [77, 5...          airplane\n",
      "123   [[217, 47, 2], [189, 33, 1], [178, 31, 1], [98...          airplane\n",
      "841   [[214, 35, 2], [184, 34, 1], [89, 49, 1], [90,...          airplane\n",
      "177   [[114, 40, 2], [119, 28, 1], [141, 0, 1], [149...          airplane\n",
      "364   [[4, 50, 2], [59, 53, 1], [203, 48, 1], [6, 49...          airplane\n",
      "723   [[247, 82, 2], [235, 79, 1], [210, 79, 1], [19...          airplane\n",
      "100   [[93, 67, 2], [104, 0, 1], [117, 9, 1], [126, ...          airplane\n",
      "603   [[172, 67, 2], [187, 65, 1], [245, 72, 1], [25...          airplane\n",
      "872   [[110, 64, 2], [67, 60, 1], [25, 71, 1], [15, ...          airplane\n",
      "924   [[0, 110, 2], [2, 103, 1], [9, 98, 1], [72, 78...          airplane\n",
      "1028  [[227, 32, 2], [39, 33, 1], [12, 39, 1], [2, 4...          airplane\n",
      "932   [[176, 55, 2], [152, 50, 1], [120, 51, 1], [22...          airplane\n",
      "848   [[115, 54, 2], [130, 25, 1], [133, 0, 1], [137...          airplane\n",
      "15    [[98, 29, 2], [122, 12, 1], [153, 0, 1], [154,...          airplane\n",
      "334   [[17, 128, 2], [4, 97, 1], [0, 66, 1], [2, 56,...          airplane\n",
      "712   [[130, 83, 2], [133, 38, 1], [139, 14, 1], [14...          airplane\n",
      "204   [[122, 108, 2], [93, 132, 1], [63, 167, 1], [6...          airplane\n",
      "887   [[51, 60, 2], [28, 61, 1], [7, 79, 1], [1, 90,...          airplane\n",
      "1063  [[144, 48, 2], [77, 39, 1], [36, 43, 1], [13, ...          airplane\n",
      "36    [[0, 104, 2], [20, 92, 1], [54, 82, 1], [138, ...          airplane\n",
      "984   [[22, 101, 2], [171, 102, 1], [207, 108, 1], [...          airplane\n",
      "...                                                 ...               ...\n",
      "965   [[117, 17, 2], [125, 8, 1], [136, 3, 1], [164,...  animal migration\n",
      "455   [[0, 108, 2], [4, 131, 1], [17, 156, 1], [21, ...  animal migration\n",
      "812   [[141, 10, 2], [127, 10, 1], [126, 25, 1], [13...  animal migration\n",
      "757   [[40, 74, 2], [83, 74, 1], [98, 86, 1], [112, ...  animal migration\n",
      "666   [[255, 19, 2], [250, 13, 1], [224, 14, 1], [21...  animal migration\n",
      "1027  [[0, 144, 2], [12, 141, 1], [45, 120, 1], [45,...  animal migration\n",
      "169   [[0, 17, 2], [0, 17, 1], [29, 7, 2], [41, 17, ...  animal migration\n",
      "208   [[21, 74, 2], [50, 74, 1], [83, 79, 1], [24, 7...  animal migration\n",
      "251   [[0, 69, 2], [11, 64, 1], [23, 63, 1], [30, 73...  animal migration\n",
      "89    [[0, 30, 2], [13, 37, 1], [9, 28, 1], [11, 23,...  animal migration\n",
      "858   [[0, 160, 2], [0, 160, 1], [0, 160, 2], [3, 13...  animal migration\n",
      "1026  [[181, 1, 2], [197, 1, 1], [207, 4, 1], [223, ...  animal migration\n",
      "877   [[0, 96, 2], [4, 86, 1], [20, 78, 1], [37, 94,...  animal migration\n",
      "52    [[78, 94, 2], [94, 52, 1], [112, 52, 1], [120,...  animal migration\n",
      "141   [[102, 33, 2], [145, 32, 1], [224, 21, 1], [17...  animal migration\n",
      "937   [[3, 22, 2], [0, 21, 1], [3, 13, 1], [16, 4, 1...  animal migration\n",
      "763   [[1, 27, 2], [7, 26, 1], [44, 37, 1], [55, 42,...  animal migration\n",
      "82    [[17, 34, 2], [17, 17, 1], [21, 10, 1], [44, 0...  animal migration\n",
      "71    [[73, 13, 2], [78, 3, 1], [84, 3, 1], [87, 21,...  animal migration\n",
      "317   [[193, 80, 2], [143, 71, 1], [116, 74, 1], [99...  animal migration\n",
      "1069  [[89, 27, 2], [89, 21, 1], [97, 14, 1], [118, ...  animal migration\n",
      "803   [[47, 216, 2], [40, 216, 1], [40, 222, 1], [45...  animal migration\n",
      "378   [[32, 2, 2], [29, 3, 1], [43, 35, 2], [0, 33, ...  animal migration\n",
      "234   [[6, 48, 2], [13, 36, 1], [21, 33, 1], [37, 35...  animal migration\n",
      "444   [[0, 59, 2], [20, 52, 1], [42, 54, 1], [54, 61...  animal migration\n",
      "572   [[240, 5, 2], [240, 4, 1], [235, 2, 2], [231, ...  animal migration\n",
      "1100  [[141, 79, 2], [150, 87, 1], [174, 96, 1], [15...  animal migration\n",
      "210   [[0, 7, 2], [12, 0, 1], [20, 0, 1], [29, 6, 1]...  animal migration\n",
      "454   [[20, 39, 2], [14, 32, 1], [10, 20, 1], [14, 5...  animal migration\n",
      "896   [[255, 6, 2], [247, 2, 1], [210, 1, 1], [187, ...  animal migration\n",
      "\n",
      "[3000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = read_batch(**valid_args)\n",
    "test_df = read_batch(**test_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode labels with value between 0 and n_classes-1.\n",
    "word_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_encoder.fit(train_df['word'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words 4 => airplane, alarm clock, ambulance, animal migration\n"
     ]
    }
   ],
   "source": [
    "print('words', len(word_encoder.classes_), '=>', ', '.join([x for x in word_encoder.classes_]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

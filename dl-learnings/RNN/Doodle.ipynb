{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traditional neural networks can’t do this, and it seems like a major shortcoming. For example, imagine you want to \n",
    "#classify what kind of event is happening at every point in a movie. It’s unclear how a traditional neural \n",
    "#network could use its reasoning about previous events in the film to inform later ones.\n",
    "\n",
    "#Recurrent neural networks address this issue. They are networks with loops in them, allowing information to persist.\n",
    "\n",
    "#LSTMs are explicitly designed to avoid the long-term dependency problem. \n",
    "#Remembering information for long periods of time is practically their default behavior, \n",
    "#not something they struggle to learn!\n",
    "\n",
    "# Best Read http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "# THE BELOW PROBLEM CAN BE SOLVED USING CNN ALSO. \n",
    "# But it is worth to solve using LSTM.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decalring Model Parameters\n",
    "batch_size = 4096\n",
    "STROKE_COUNT = 196\n",
    "TRAIN_SAMPLES = 750\n",
    "VALID_SAMPLES = 75\n",
    "TEST_SAMPLES = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing standard libraries \n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#A metric is a function that is used to judge the performance of your model. \n",
    "#Metric functions are to be supplied in the metrics parameter when a model is compiled.\n",
    "\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "\n",
    "#Available metrics\n",
    "#binary_accuracy , categorical_accuracy, sparse_categorical_accuracy, top_k_categorical_accuracy, \n",
    "#sparse_top_k_categorical_accuracy\n",
    "\n",
    "#AND \n",
    "\n",
    "#Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_accuracy(x,y): return top_k_categorical_accuracy(x,y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A callback is a set of functions to be applied at given stages of the training procedure. \n",
    "#You can use callbacks to get a view on internal states and statistics of the model during training. \n",
    "#You can pass a list of callbacks (as the keyword argument callbacks) to the .fit() method \n",
    "#of the Sequential or Model classes. The relevant methods of the callbacks will then be called \n",
    "#at each stage of the training.\n",
    "\n",
    "# ModelCheckpoint - Save the model after every epoch.\n",
    "# LearningRateScheduler - Learning rate scheduler.\n",
    "# EarlyStopping - top training when a monitored quantity has stopped improving.\n",
    "# ReduceLROnPlateau - Reduce learning rate when a metric has stopped improving.\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from glob import glob\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for available GPU, but for our learnings lets skip this.\n",
    "def get_available_gpus():\n",
    "    from tensorflow.python.client import device_lib\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\..\\\\data\\\\doodleoutput'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = '..\\..\\data\\doodleoutput'\n",
    "base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
